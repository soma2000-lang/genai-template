# yaml-language-server: $schema=https://promptfoo.dev/config-schema.json

# Red teaming configuration

# Docs: https://promptfoo.dev/docs/red-team/configuration
description: "My first red team"

# or targets. generates the output
providers:
  # Red team targets. To talk directly to your application, use a custom provider.
  # See https://promptfoo.dev/docs/red-team/configuration/#providers
  - id: azureopenai:chat:{{env.AZURE_OPENAI_DEPLOYMENT_NAME}}
    label: '{{env.AZURE_OPENAI_DEPLOYMENT_NAME}}'


# Other redteam settings
redteam:
  # attacker provider: generates adversial outputs. Some providers such as Anthropic may disable your account for generating harmful test cases. We recommend using the default OpenAI provider.
  provider:
    id: azureopenai:chat:phi3:3.8b-mini-4k-instruct-q4_K_M

  purpose: "travel test app"
  # Default number of inputs to generate for each plugin.
  # The total number of tests will be (numTests * plugins.length * (1 + strategies.length))
  numTests: 1   # Each plugin generates 1 adversarial inputs.

  # To control the number of tests for each plugin, use:
  # - id: plugin-name
  #   numTests: 10
  plugins:
    - hallucination  # Model generating false or misleading information
    - harmful:hate  # Content that promotes hate or discrimination
#
#
#  # Attack methods for applying adversarial inputs
#  strategies:
#    - jailbreak # Attempts to bypass security measures through iterative prompt refinement
#    - prompt-injection # Malicious inputs designed to manipulate the model's behavior

#defaultTest:
#  options:
#    # grader/ evaluator : evaluates the generated outputs if llm-rubric metrics are used moderation
#    provider:
#      id: azureopenai:chat:{{env.AZURE_OPENAI_DEPLOYMENT_NAME}}
